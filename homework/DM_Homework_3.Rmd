---
title: "Homework 3"
author: "Christina Ridlen"
date: "`r Sys.Date()`"
output: md_document
---

# What causes what?

```{r libraries, include = FALSE}
library(tidymodels)
library(tidyverse)
library(rpart.plot)
library(pdp)
```

# Tree modeling: dengue cases

```{r dengue_data, include = FALSE}
# Load data
dengue <- read_csv("../data/dengue.csv")
# Remove missing values
dengue <- dengue[complete.cases(dengue),]
# Treat categorical variables
dengue$city <- factor(dengue$city)
dengue$season <- factor(dengue$season)
```

```{r CART, include = FALSE}

# Create regression tree
cart_spec <- decision_tree() %>%
  set_mode("regression") %>%
  set_engine("rpart")


# Train-test split
dengue_split <- initial_split(dengue, prop = 0.8, strata = total_cases)
dengue_train <- training(dengue_split)
dengue_test <- testing(dengue_split)

# Choose best model
tune_spec <- decision_tree(tree_depth = tune(),
                           cost_complexity = tune()) %>%
  set_mode("regression") %>%
  set_engine("rpart")

# Tuning grid
tree_grid <- grid_regular(parameters(tune_spec),
                          levels = 4)
tree_grid

# Tune along the grid
folds <- vfold_cv(dengue_train, v = 10)
tune_results <- tune_grid(tune_spec,
                          total_cases ~ .,
                          resamples = folds,
                          grid = tree_grid,
                          metrics = metric_set(rmse))

# Find best model
# Fit to training data
final_params <- select_best(tune_results)
best_spec <- finalize_model(tune_spec, final_params)
cart_final <- fit(best_spec,
                 total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
                 data = dengue_train)

cart_final 
view(final_params)


# In-sample performance
in_dengue_cart <- predict(cart_final, dengue_train) %>%
  bind_cols(dengue_train)

rmse(in_dengue_cart,
     estimate = .pred,
     truth = total_cases)

# Out-of-sample performance
out_dengue_cart <- predict(cart_final, dengue_test) %>%
  bind_cols(dengue_test)

rmse_out_cart <- rmse(out_dengue_cart,
     estimate = .pred,
     truth = total_cases)
rmse_out_cart
```

### Comparisons

The CART model was fit with the formula `total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt` using the training data. I used the `tidymodels` package and `rpart` engine to specify the decision tree. After fitting the model, I identified the optimal cost complexity and tree depth parameters that would minimize the RMSE through cross-validation. The model was then pruned so that the final decision tree used the optimal parameters `cp = 1e=-10` and `tree_depth =5`. Finally, the in-sample performance was calculated after cross-validation using the training data, and out-of-sample performance was calculated using the testing data.

To fit the random forests model, the same formula `total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt` was used on the training data. I calculated the in-sample and out-of-sample performances for this model. Fitting the boosted tree model was similar, and the in-sample and out-of-sample performances for the three models are summarized below.

```{r random_forests, include = FALSE}
# Specify model
rand_spec <- rand_forest() %>%
  set_mode("regression") %>%
  set_engine("ranger")

# Train model

model_rand <- rand_spec %>%
  fit(total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
      data = dengue_train)

# Cross-validated in sample performance

set.seed(50)
rand_cv <- fit_resamples(rand_spec,
                         total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
                         resamples = folds,
                         metrics = metric_set(rmse))
collect_metrics(rand_cv, summarize = TRUE)

# Out-of-sample performance

out_dengue_rand <- predict(model_rand, dengue_test) %>%
  bind_cols(dengue_test)

rmse_out_rand <- rmse(out_dengue_rand,
                      estimate = .pred,
                      truth = total_cases) 
rmse_out_rand
```

```{r boosted, include = FALSE}

# Specify
boost_spec <- boost_tree() %>%
  set_mode("regression") %>%
  set_engine("xgboost")

# Train model
boost_model <- fit(boost_spec,
                   total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
                   dengue_train)

# CV
set.seed(100)
boost_cv <- fit_resamples(boost_spec,
                            total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
                            resamples = dengue_folds,
                            metrics = metric_set(rmse))
collect_metrics(boost_cv, summarize = TRUE)

# Out of Sample
out_dengue_boost <- predict(boost_model, dengue_test)  %>%
  bind_cols(dengue_test)

rmse_out_boost <- rmse(out_dengue_boost,
                       estimate = .pred,
                       truth = total_cases)
rmse_out_boost
```

```{r tree_table}
# Create table listing in-sample and out of sample performance of tree models


```

The random forests model has the lowest out of sample RMSE. So we use this model for the partial dependence plots:

```{r pdp_2, echo = FALSE}



```

# Predictive model building: green certification

```{r green_data, include = FALSE}

# Load data
greenbuildings <- read_csv("../data/greenbuildings.csv")

# Categorical variables to factors
glimpse(greenbuildings)
greenbuildings <- greenbuildings %>%
  mutate(CS_PropertyID = factor(CS_PropertyID),
         cluster = factor(cluster))
# Train test split
green_split <- initial_split(greenbuildings, prop = 0.8)
green_train <- training(green_split)
green_test <- testing(green_split)
```

```{r green_bagged}

```
