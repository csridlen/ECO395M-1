---
title: "Homework 3"
author: "Christina Ridlen"
date: "`r Sys.Date()`"
output: md_document
---

```{r libraries, include = FALSE}
library(tidymodels)
library(tidyverse)
library(rpart.plot)
library(pdp)
library(glmnet)
setwd("C:/Users/tinar/ECO395M-Homework/homework")
```

# What causes what?

1.  The regression estimates will be highly biased because the correlation between crime and number of police in a city is extremely high. We could not establish causality with this regression.
2.  The researchers from UPenn found a scenario in which number of police is *not* caused by crime rate. Specifically, in Washington, D.C., the city is on "High Alert" if the risk of terrorism at the time is high. Thus the number of police stationed in the city is high and unrelated to hte actual level of crime that occurs. Their regression shows that when policy presence is high, the crime level decreases.
3.  The researchers controlled for the possibility that people might not be outside in the D.C. area during High Alert times. In Table 2, they find that even after controlling for number of people active in the city, the level of crime still decreases at a significant level when police presence is high.
4.  

# Tree modeling: dengue cases

```{r dengue_data, include = FALSE}
# Load data
dengue <- read_csv("../data/dengue.csv")
# Remove missing values
dengue <- dengue[complete.cases(dengue),]
# Treat categorical variables
dengue$city <- factor(dengue$city)
dengue$season <- factor(dengue$season)
```

```{r CART, include = FALSE}

# Create regression tree
cart_spec <- decision_tree() %>%
  set_mode("regression") %>%
  set_engine("rpart")


# Train-test split
dengue_split <- initial_split(dengue, prop = 0.8, strata = total_cases)
dengue_train <- training(dengue_split)
dengue_test <- testing(dengue_split)

# Choose best model
tune_spec <- decision_tree(tree_depth = tune(),
                           cost_complexity = tune()) %>%
  set_mode("regression") %>%
  set_engine("rpart")

# Tuning grid
tree_grid <- grid_regular(parameters(tune_spec),
                          levels = 4)
tree_grid

# Tune along the grid
folds <- vfold_cv(dengue_train, v = 10)
tune_results <- tune_grid(tune_spec,
                          total_cases ~ .,
                          resamples = folds,
                          grid = tree_grid,
                          metrics = metric_set(rmse))

# Find best model
# Fit to training data
final_params <- select_best(tune_results)
best_spec <- finalize_model(tune_spec, final_params)
cart_final <- fit(best_spec,
                 total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
                 data = dengue_train)

cart_final 
view(final_params)


# In-sample performance
in_dengue_cart <- predict(cart_final, dengue_train) %>%
  bind_cols(dengue_train)

rmse(in_dengue_cart,
     estimate = .pred,
     truth = total_cases)

# Out-of-sample performance
out_dengue_cart <- predict(cart_final, dengue_test) %>%
  bind_cols(dengue_test)

rmse_out_cart <- rmse(out_dengue_cart,
     estimate = .pred,
     truth = total_cases)
rmse_out_cart
```

### Comparisons

The CART model was fit with the formula `total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt` using the training data. I used the `tidymodels` package and `rpart` engine to specify the decision tree. After fitting the model, I identified the optimal cost complexity and tree depth parameters that would minimize the RMSE through cross-validation. The model was then pruned so that the final decision tree used the optimal parameters `cp = 1e=-10` and `tree_depth =5`. Finally, the in-sample performance was calculated after cross-validation using the training data, and out-of-sample performance was calculated using the testing data.

To fit the random forests model, the same formula `total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt` was used on the training data. I calculated the in-sample and out-of-sample performances for this model. Fitting the boosted tree model was similar, and the in-sample and out-of-sample performances for the three models are summarized below.

```{r random_forests, include = FALSE}
# Specify model
rand_spec <- rand_forest() %>%
  set_mode("regression") %>%
  set_engine("ranger")

# Train model

model_rand <- rand_spec %>%
  fit(total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
      data = dengue_train)

# Cross-validated in sample performance

set.seed(50)
rand_cv <- fit_resamples(rand_spec,
                         total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
                         resamples = folds,
                         metrics = metric_set(rmse))
collect_metrics(rand_cv, summarize = TRUE)

# Out-of-sample performance

out_dengue_rand <- predict(model_rand, dengue_test) %>%
  bind_cols(dengue_test)

rmse_out_rand <- rmse(out_dengue_rand,
                      estimate = .pred,
                      truth = total_cases) 
rmse_out_rand
```

```{r boosted, include = FALSE}

# Specify
boost_spec <- boost_tree() %>%
  set_mode("regression") %>%
  set_engine("xgboost")

# Train model
boost_model <- fit(boost_spec,
                   total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
                   dengue_train)

# CV
set.seed(100)
boost_cv <- fit_resamples(boost_spec,
                            total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt,
                            resamples = dengue_folds,
                            metrics = metric_set(rmse))
collect_metrics(boost_cv, summarize = TRUE)

# Out of Sample
out_dengue_boost <- predict(boost_model, dengue_test)  %>%
  bind_cols(dengue_test)

rmse_out_boost <- rmse(out_dengue_boost,
                       estimate = .pred,
                       truth = total_cases)
rmse_out_boost
```

```{r tree_table}
# Create table listing in-sample and out of sample performance of tree models


```

The random forests model has the lowest out of sample RMSE. So we use this model for the partial dependence plots:

```{r pdp_2, echo = FALSE}



```

# Predictive model building: green certification

```{r green_data, include = FALSE}

# Load data
greenbuildings <- read_csv("../data/greenbuildings.csv")

# Categorical variables to factors
glimpse(greenbuildings)
greenbuildings <- greenbuildings %>%
  mutate(CS_PropertyID = factor(CS_PropertyID),
         cluster = factor(cluster))

# Create revenue per square foot variable
greenbuildings <- greenbuildings %>%
  mutate(revenue_sqft = Rent*leasing_rate)

# Remove rent and leasing rate
# greenbuildings <- subset(greenbuildings, select = -c(Rent, leasing_rate))

#Remove missing values
greenbuildings <- greenbuildings[complete.cases(greenbuildings),]


# Train test split
set.seed(100)
green_split <- initial_split(greenbuildings, prop = 0.8, strata = revenue_sqft)
green_train <- training(green_split)
green_test <- testing(green_split)
```

First, I created the revenue per square foot variable `revenue_sqft` by multiplying `Rent` and `leasing_rate`. In order to isolate the effects of all other predictor variables, I naturally removed these variables from the dataset. However, upon running a Random Forest regression, the out-of-sample RMSE was more than twice the RMSE of the in-sample predictions. I then ran the Random Forest model again, this time including rent and leasing rate, to see what the issue was:

```{r green_rf, echo = FALSE}
rand_spec <- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = tune()) %>%
  set_mode("regression") %>%
  set_engine("ranger", importance = "impurity")

# Get rid of the unknown
rf_param <- rand_spec %>%
  parameters()
rf_param <-
  rf_param %>%
  finalize(x = green_train)

# Create tuning grid
tunegrid_rand <- grid_regular(rf_param,
                              levels = 2)
green_folds <- vfold_cv(green_train, v = 5)
tune_results <- tune_grid(rand_spec,
                          revenue_sqft ~ .,
                          resamples = green_folds,
                          grid = tunegrid_rand,
                          metrics = metric_set(rmse))
best_rand_params <- select_best(tune_results)
final_spec <- finalize_model(rand_spec, best_rand_params)
rand_model <- final_spec %>% fit(formula = revenue_sqft ~ ., data = green_train)

# In-sample performance
pred_insample <- predict(rand_model,
                         green_train) %>%
  bind_cols(green_train)

rmse_in_rf <- rmse(pred_insample,
     estimate = .pred,
     truth = revenue_sqft)

# Out performance
pred_outsample <- predict(rand_model,
                          green_test) %>%
  bind_cols(green_test)

rmse_out_rf <- rmse(pred_outsample,
     estimate = .pred,
     truth = revenue_sqft)

# Variable importance plot
vip::vip(rand_model)
```

The variable importance plot shows that `Rent` and `leasing_rate` are overwhelming any predictive power of the other variables. I perform a lasso regression next to allow R to select important variables itself.

```{r lasso_green, include = FALSE}

x = model.matrix(revenue_sqft ~ . -CS_PropertyID - cluster, data = greenbuildings)
y = greenbuildings$revenue_sqft

xtrain = model.matrix(revenue_sqft ~ . -CS_PropertyID - cluster, data = green_train)
ytrain = green_train$revenue_sqft

xtest = model.matrix(revenue_sqft ~ . -CS_PropertyID - cluster, data = green_test)
ytest = green_test$revenue_sqft

#### Lasso regression

grid <- 10^seq(10, -2, length  = 100)
lasso = glmnet(xtrain, ytrain, alpha = 1, lambda = grid)


# cross-validated lasso
set.seed(123)
cv_out <- cv.glmnet(xtrain, ytrain, alpha = 1)
best_l <-cv_out$lambda.min

# in-sample predictions
cv_pred <- predict(cv_out, c = best_l,
                   newx = xtrain)
rmse_cv <- mean(sqrt((cv_pred - ytrain)^2))
rmse_cv

# out of sample
lasso_pred <- predict(lasso, s = best_l,
                      newx = xtest)

rmse_lasso <- mean(sqrt((lasso_pred - ytest)^2))
rmse_lasso

# obtain coefficient estimates

lasso_out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso_coef <- predict(lasso, type = "coefficients", 
                      s = best_l)[1:20, ]
lasso_coef
lasso_coef["green_rating"]
```

Without rent and leasing rate

```{r green_data_removed, include= FALSE}
# Load data
greenbuildings <- read_csv("../data/greenbuildings.csv")

# Categorical variables to factors
glimpse(greenbuildings)
greenbuildings <- greenbuildings %>%
  mutate(CS_PropertyID = factor(CS_PropertyID),
         cluster = factor(cluster))

# Create revenue per square foot variable
greenbuildings <- greenbuildings %>%
  mutate(revenue_sqft = Rent*leasing_rate)

# Remove rent and leasing rate
greenbuildings <- subset(greenbuildings, select = -c(Rent, leasing_rate))

#Remove missing values
greenbuildings <- greenbuildings[complete.cases(greenbuildings),]


# Train test split
set.seed(100)
green_split <- initial_split(greenbuildings, prop = 0.8, strata = revenue_sqft)
green_train <- training(green_split)
green_test <- testing(green_split)
```

```{r green_rf_wo, include = FALSE}

rand_spec <- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = tune()) %>%
  set_mode("regression") %>%
  set_engine("ranger", importance = "impurity")

# Get rid of the unknown
rf_param <- rand_spec %>%
  parameters()
rf_param <-
  rf_param %>%
  finalize(x = green_train)

# Create tuning grid
tunegrid_rand <- grid_regular(rf_param,
                              levels = 2)
green_folds <- vfold_cv(green_train, v = 5)
tune_results <- tune_grid(rand_spec,
                          revenue_sqft ~ .,
                          resamples = green_folds,
                          grid = tunegrid_rand,
                          metrics = metric_set(rmse))
best_rand_params <- select_best(tune_results)
final_spec <- finalize_model(rand_spec, best_rand_params)
rand_model <- final_spec %>% fit(formula = revenue_sqft ~ ., data = green_train)

# In-sample performance
pred_insample <- predict(rand_model,
                         green_train) %>%
  bind_cols(green_train)

rmse(pred_insample,
     estimate = .pred,
     truth = revenue_sqft)

# Out performance
pred_outsample <- predict(rand_model,
                          green_test) %>%
  bind_cols(green_test)

rmse(pred_outsample,
     estimate = .pred,
     truth = revenue_sqft)

# Variable importance plot
vip::vip(rand_model)
```

```{r lasso_green_wo, include = FALSE}

x = model.matrix(revenue_sqft ~ . -CS_PropertyID - cluster, data = greenbuildings)
y = greenbuildings$revenue_sqft

xtrain = model.matrix(revenue_sqft ~ . -CS_PropertyID - cluster, data = green_train)
ytrain = green_train$revenue_sqft

xtest = model.matrix(revenue_sqft ~ . -CS_PropertyID - cluster, data = green_test)
ytest = green_test$revenue_sqft

#### Lasso regression

grid <- 10^seq(10, -2, length  = 100)
lasso = glmnet(xtrain, ytrain, alpha = 1, lambda = grid)


# cross-validated lasso
set.seed(123)
cv_out <- cv.glmnet(xtrain, ytrain, alpha = 1)
best_l <-cv_out$lambda.min

# in-sample predictions
cv_pred <- predict(cv_out, c = best_l,
                   newx = xtrain)
rmse_cv <- mean(sqrt((cv_pred - ytrain)^2))
rmse_cv

# out of sample
lasso_pred <- predict(lasso, s = best_l,
                      newx = xtest)

rmse_lasso <- mean(sqrt((lasso_pred - ytest)^2))
rmse_lasso

# obtain coefficient estimates

lasso_out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso_coef <- predict(lasso, type = "coefficients", 
                      s = best_l)[1:20, ]
lasso_coef
lasso_coef["green_rating"]
```

I then ran a lasso regression, since there seems to be high multicollinearity within many of the variables. The RMSE was high, but there was no longer evidence of overfitting. I then ran random forest and lasso regressions again, including `Rent` and `leasing_rate` in the regression.

+--------------------------------------------+--------------+--------------+
| Model                                      | RMSE in      | RMSE out     |
+============================================+==============+==============+
| Lasso (with rent, leasing rate)            | 125          | 128          |
+--------------------------------------------+--------------+--------------+
| Lasso (without rent, leasing rate)         | 622          | 625          |
+--------------------------------------------+--------------+--------------+
| Random Forest (with rent, leasing rate)    | 72           | 86           |
+--------------------------------------------+--------------+--------------+
| Random Forest (without rent, leasing rate) | 288          | 710          |
+--------------------------------------------+--------------+--------------+

What we notice in the table is that by excluding rent and leasing rate from the regression is that the variance of the estimates increases. This is obvious due to the overfitting of the random forest model even when R chooses the optimal tree depth and number of randomly selected predictors. The lasso regression performs similarly in and out of sample. But with the exclusion of rent and leasing rate, the model has a harder time predicting what the revenue per square foot of the building will be, so the variance increases. However, we can better isolate the effects of predictor variables that are not almost perfectly correlated with our response variable `revenue_sqft`. I include the lasso regression estimates both including and excluding rent and leasing rate:

+-----------------------------------------+-------------------------------------+------------------------------------------------+
| Lasso estimate of `green_rating` (with) | **Lasso estimate of `LEED` (with)** | **Lasso estimate of `green_rating` (without)** |
+=========================================+=====================================+================================================+
| 0                                       | -26                                 | 194                                            |
+-----------------------------------------+-------------------------------------+------------------------------------------------+

So holding all else constant, having a green rating increases revenue per square foot (per calendar year) by \$194.

I include the summary statistics of `revenue_sqft` for reference:

```{r summ_table, echo = FALSE}
summ <- c(summary(greenbuildings$revenue_sqft))
summ_df <- data.frame(summ)
knitr::kable(summ_df, caption = "Summary Statistics for Revenue per Square Foot per Calendar Year")
```
